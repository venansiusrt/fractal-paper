{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6eb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Constants\n",
    "PATH = \"D://Mandelbrot Project\"\n",
    "TAIL = 1\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 256\n",
    "PATIENCE = 3\n",
    "\n",
    "def build_1d_cnn():\n",
    "    model = Sequential([\n",
    "        # Input shape: (timesteps, features) = (2, 1)\n",
    "        Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(TAIL, 1)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Global pooling avoids dimension reduction issues\n",
    "        GlobalMaxPooling1D(),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def load_data(typ):\n",
    "    try:\n",
    "        if typ == 'test':\n",
    "            filepath = f\"{PATH}//Julia_Dataset_TestPy.csv\"\n",
    "            target_col = 'target'\n",
    "        else:\n",
    "            filepath = f\"{PATH}//New_Julia_Dataset_TrainPy_10000_{typ}.csv\"\n",
    "            target_col = '8'\n",
    "        \n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Fallback to last column if target not found\n",
    "        if target_col not in df.columns:\n",
    "            target_col = df.columns[-1]\n",
    "            \n",
    "        X = df.iloc[:, :TAIL].values.astype(np.float32)\n",
    "        y = df[target_col].values.astype(np.float32)\n",
    "        \n",
    "        # Reshape for 1D CNN: (samples, timesteps, channels)\n",
    "        X = X.reshape(X.shape[0], TAIL, 1)\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data {typ}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "    \n",
    "    # Outer progress bar for datasets\n",
    "    for typ in tqdm(range(10), desc=\"Datasets\"):\n",
    "        try:\n",
    "            # Load data with progress indication\n",
    "            X_train, y_train = load_data(typ)\n",
    "            X_test, y_test = load_data('test')\n",
    "            \n",
    "            if X_train is None:\n",
    "                results.append({'type': typ, 'error': 'Data load failed'})\n",
    "                continue\n",
    "                \n",
    "            # Build and train model\n",
    "            model = build_1d_cnn()\n",
    "            \n",
    "            # Training with progress bar\n",
    "            start_time = time.time()\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                callbacks=[EarlyStopping(patience=PATIENCE)],\n",
    "                verbose=1  # Shows epoch progress\n",
    "            )\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'type': typ,\n",
    "                'train_acc': round(history.history['accuracy'][-1] * 100, 2),\n",
    "                'test_acc': round(history.history['val_accuracy'][-1] * 100, 2),\n",
    "                'time_sec': round(elapsed, 2)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError in dataset {typ}: {str(e)}\")\n",
    "            results.append({'type': typ, 'error': str(e)})\n",
    "    \n",
    "    # Save and show results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(results_df)\n",
    "    results_df.to_csv(f\"{PATH}//1D_CNN_Results_Final.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PATH = \"D://ITS//Mandelbrot Project//Violin Plot//Dataset K=3 and N=10000\"\n",
    "TAIL = 2\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 256\n",
    "PATIENCE = 3\n",
    "\n",
    "def build_1d_cnn():\n",
    "    \"\"\"Build 1D CNN that works with TAIL=2 input size\"\"\"\n",
    "    model = Sequential([\n",
    "        # Input shape: (timesteps, features) = (2, 1)\n",
    "        Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(TAIL, 1)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Global pooling avoids dimension reduction issues\n",
    "        GlobalMaxPooling1D(),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def load_data(typ):\n",
    "    \"\"\"Load and prepare data for CNN\"\"\"\n",
    "    try:\n",
    "        if typ == 'test':\n",
    "            filepath = f\"{PATH}//Julia_Dataset_TestPy.csv\"\n",
    "            target_col = 'target'\n",
    "        else:\n",
    "            filepath = f\"{PATH}//New_Julia_Dataset_TrainPy_10000_{typ}.csv\"\n",
    "            target_col = '8'\n",
    "        \n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Fallback to last column if target not found\n",
    "        if target_col not in df.columns:\n",
    "            target_col = df.columns[-1]\n",
    "            \n",
    "        X = df.iloc[:, :TAIL].values.astype(np.float32)\n",
    "        y = df[target_col].values.astype(np.float32)\n",
    "        \n",
    "        # Reshape for 1D CNN: (samples, timesteps, channels)\n",
    "        X = X.reshape(X.shape[0], TAIL, 1)\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data {typ}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "    \n",
    "    # Outer progress bar for datasets\n",
    "    for typ in tqdm(range(10), desc=\"Datasets\"):\n",
    "        try:\n",
    "            # Load data with progress indication\n",
    "            X_train, y_train = load_data(typ)\n",
    "            X_test, y_test = load_data('test')\n",
    "            \n",
    "            if X_train is None:\n",
    "                results.append({'type': typ, 'error': 'Data load failed'})\n",
    "                continue\n",
    "                \n",
    "            # Build and train model\n",
    "            model = build_1d_cnn()\n",
    "            \n",
    "            # Training with progress bar\n",
    "            start_time = time.time()\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                callbacks=[EarlyStopping(patience=PATIENCE)],\n",
    "                verbose=1  # Shows epoch progress\n",
    "            )\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'type': typ,\n",
    "                'train_acc': round(history.history['accuracy'][-1] * 100, 2),\n",
    "                'test_acc': round(history.history['val_accuracy'][-1] * 100, 2),\n",
    "                'time_sec': round(elapsed, 2)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError in dataset {typ}: {str(e)}\")\n",
    "            results.append({'type': typ, 'error': str(e)})\n",
    "    \n",
    "    # Save and show results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(results_df)\n",
    "    results_df.to_csv(f\"{PATH}//1D_CNN_Results_Final.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Constants\n",
    "PATH = \"D://ITS//Mandelbrot Project//Violin Plot//Dataset K=3 and N=10000\"\n",
    "TAIL = 3\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 256\n",
    "PATIENCE = 3\n",
    "\n",
    "def build_1d_cnn():\n",
    "    \"\"\"Build 1D CNN that works with TAIL=2 input size\"\"\"\n",
    "    model = Sequential([\n",
    "        # Input shape: (timesteps, features) = (2, 1)\n",
    "        Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(TAIL, 1)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Global pooling avoids dimension reduction issues\n",
    "        GlobalMaxPooling1D(),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def load_data(typ):\n",
    "    \"\"\"Load and prepare data for CNN\"\"\"\n",
    "    try:\n",
    "        if typ == 'test':\n",
    "            filepath = f\"{PATH}//Julia_Dataset_TestPy.csv\"\n",
    "            target_col = 'target'\n",
    "        else:\n",
    "            filepath = f\"{PATH}//New_Julia_Dataset_TrainPy_10000_{typ}.csv\"\n",
    "            target_col = '8'\n",
    "        \n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Fallback to last column if target not found\n",
    "        if target_col not in df.columns:\n",
    "            target_col = df.columns[-1]\n",
    "            \n",
    "        X = df.iloc[:, :TAIL].values.astype(np.float32)\n",
    "        y = df[target_col].values.astype(np.float32)\n",
    "        \n",
    "        # Reshape for 1D CNN: (samples, timesteps, channels)\n",
    "        X = X.reshape(X.shape[0], TAIL, 1)\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data {typ}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "    \n",
    "    # Outer progress bar for datasets\n",
    "    for typ in tqdm(range(10), desc=\"Datasets\"):\n",
    "        try:\n",
    "            # Load data with progress indication\n",
    "            X_train, y_train = load_data(typ)\n",
    "            X_test, y_test = load_data('test')\n",
    "            \n",
    "            if X_train is None:\n",
    "                results.append({'type': typ, 'error': 'Data load failed'})\n",
    "                continue\n",
    "                \n",
    "            # Build and train model\n",
    "            model = build_1d_cnn()\n",
    "            \n",
    "            # Training with progress bar\n",
    "            start_time = time.time()\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                callbacks=[EarlyStopping(patience=PATIENCE)],\n",
    "                verbose=1  # Shows epoch progress\n",
    "            )\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'type': typ,\n",
    "                'train_acc': round(history.history['accuracy'][-1] * 100, 2),\n",
    "                'test_acc': round(history.history['val_accuracy'][-1] * 100, 2),\n",
    "                'time_sec': round(elapsed, 2)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError in dataset {typ}: {str(e)}\")\n",
    "            results.append({'type': typ, 'error': str(e)})\n",
    "    \n",
    "    # Save and show results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(results_df)\n",
    "    results_df.to_csv(f\"{PATH}//1D_CNN_Results_Final.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Constants\n",
    "PATH = \"D://ITS//Mandelbrot Project//Violin Plot//Dataset K=3 and N=10000\"\n",
    "TAIL = 4\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 256\n",
    "PATIENCE = 3\n",
    "\n",
    "def build_1d_cnn():\n",
    "    \"\"\"Build 1D CNN that works with TAIL=2 input size\"\"\"\n",
    "    model = Sequential([\n",
    "        # Input shape: (timesteps, features) = (2, 1)\n",
    "        Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(TAIL, 1)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Global pooling avoids dimension reduction issues\n",
    "        GlobalMaxPooling1D(),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def load_data(typ):\n",
    "    \"\"\"Load and prepare data for CNN\"\"\"\n",
    "    try:\n",
    "        if typ == 'test':\n",
    "            filepath = f\"{PATH}//Julia_Dataset_TestPy.csv\"\n",
    "            target_col = 'target'\n",
    "        else:\n",
    "            filepath = f\"{PATH}//New_Julia_Dataset_TrainPy_10000_{typ}.csv\"\n",
    "            target_col = '8'\n",
    "        \n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Fallback to last column if target not found\n",
    "        if target_col not in df.columns:\n",
    "            target_col = df.columns[-1]\n",
    "            \n",
    "        X = df.iloc[:, :TAIL].values.astype(np.float32)\n",
    "        y = df[target_col].values.astype(np.float32)\n",
    "        \n",
    "        # Reshape for 1D CNN: (samples, timesteps, channels)\n",
    "        X = X.reshape(X.shape[0], TAIL, 1)\n",
    "        return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data {typ}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "    \n",
    "    # Outer progress bar for datasets\n",
    "    for typ in tqdm(range(10), desc=\"Datasets\"):\n",
    "        try:\n",
    "            # Load data with progress indication\n",
    "            X_train, y_train = load_data(typ)\n",
    "            X_test, y_test = load_data('test')\n",
    "            \n",
    "            if X_train is None:\n",
    "                results.append({'type': typ, 'error': 'Data load failed'})\n",
    "                continue\n",
    "                \n",
    "            # Build and train model\n",
    "            model = build_1d_cnn()\n",
    "            \n",
    "            # Training with progress bar\n",
    "            start_time = time.time()\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                callbacks=[EarlyStopping(patience=PATIENCE)],\n",
    "                verbose=1  # Shows epoch progress\n",
    "            )\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'type': typ,\n",
    "                'train_acc': round(history.history['accuracy'][-1] * 100, 2),\n",
    "                'test_acc': round(history.history['val_accuracy'][-1] * 100, 2),\n",
    "                'time_sec': round(elapsed, 2)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError in dataset {typ}: {str(e)}\")\n",
    "            results.append({'type': typ, 'error': str(e)})\n",
    "    \n",
    "    # Save and show results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(results_df)\n",
    "    results_df.to_csv(f\"{PATH}//1D_CNN_Results_Final.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
